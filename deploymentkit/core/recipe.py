
import os.path

import yaml

import deploymentkit

"""Target independent package recipe

This is similar to what the native GNU/Linux packaging systems use
(.spec, .dsc, PKGBUILD, ebuild) but different in two significant ways:

- Metadata is specified in a target independent way.
- The format is designed to be easy to access programatically.
- The format is declarative.

This target independent recipe is transformed into
a target specific recipe by DeploymentKit.

Mapping the metadata declarations to actions used to build the software
is the responsiblity of the target implementation inside DeploymentKit.

Programatic access is important so that it can be manipulated with
other tools, for instance graphically by the user in a
integrated development environment or generated by information
already found in the build-system.

Dependencies are specified using for instance:
- pkg-config
- dbus
- executable
"""

def format_defaults(format_definition):
    defaults = {}

    for attribute, definition in format_definition.items():
        mandatory, value_type, default_value, description, example_value, supported = definition

        if not default_value is None:
            defaults[attribute] = default_value

    return defaults

def format_mandatory_attributes(format_definition):
    attributes = []

    for attribute, definition in format_definition.items():
        mandatory, value_type, default_value, description, example_value, supported = definition

        if mandatory:
            attributes.append(attribute)

    return attributes

def format_optional_attributes(format_definition):
    attributes = []

    for attribute, definition in format_definition.items():
        mandatory, value_type, default_value, description, example_value, supported = definition

        if not mandatory:
            attributes.append(attribute)

    return attributes

def format_attributes(format_definition):
    attributes = []

    for attribute, definition in format_definition.items():
        attributes.append(attribute)

    return attributes

def format_example(format_definition):
    example = {}
    for key, value in format_definition.items():
        example[key] = format_definition[key][-1]
    return example

def format_documentation(format_definition):
    # Literal documentation
    metadata_documentation = ''
    doc_lines = []
    def doc_attribute_str(attribute):
       mandatory, value_type, default_value, description, example, supported = format_definition[attribute]
       return '\t%s (%s): %s' % (attribute, value_type, description)

    # Header
    doc_lines.append("The package metadata format used by DeploymentKit is based on YAML.")
    doc_lines.append("")
    doc_lines.append("")

    # Mandatory attributes
    doc_lines.append('The following attributes are mandatory:')
    for attribute in format_mandatory_attributes(format_definition):
        doc_lines.append(doc_attribute_str(attribute))

    # Optional attributes
    doc_lines.append("")
    doc_lines.append('The following attributes are optional:')
    for attribute in format_optional_attributes(format_definition):
        doc_lines.append(doc_attribute_str(attribute))

    metadata_documentation = '\n'.join(doc_lines)

    # Example
    metadata_documentation += "\n\nExample:\n\n"
    metadata_documentation += yaml.dump(format_example(format_definition))

    return metadata_documentation

def any_value(attribute_value):
    return (True, 'Any value acceptable')

def list_of_dependencies(attribute_value):
    """ """

    supported_types = ["pkg-config", "executable"]

    explanation = "Each dependency must be on form \"type:identifier\", where type is one of: %s" % str(supported_types)

    for dep in attribute_value:
        type, identifier = dep.split(":")
        if not type in supported_types:
            return (False, explanation)

    return (True, explanation)

def list_of_any_strings(attribute_value):
    """ """

    e = "List of any string values accepted."

    for string in attribute_value:
        valid, ignore = any_string(string)
        if not valid:
            return (False, e)

    return (True, e)

def any_string(attribute_value):
    """ """

    # TODO: actually validate that it is a string

    explanation = "Any string value accepted."

    return (True, explanation)

def supported_buildsystem(attribute_value):
    """ """

    # Union of all supported build systems from backends
    # FIXME: query dynamically
    supported = ['autotools', 'distutils']

    explanation = "Must be one of: %s" % str(supported)

    if attribute_value in supported:
        return (True, explanation)
    else:
        return (False, explanation)

def supported_project_type(attribute_value):
    """ """
    
    # Union of all supported project types from backends
    # FIXME: query dynamically
    supported = ['python2-library', 'python3-library',
                 'c-library', 'c-application']

    explanation = "Must be one of: %s" % str(supported)

    if attribute_value in supported:
        return (True, explanation)
    else:
        return (False, explanation)

def valid_uri(attribute_value):

    supported_schemes = ['http', 'ftp']

    # TODO: check for invalid characters
    uri = attribute_value

    try:
        scheme = uri.split('://')[0]
    except IndexError:
        return (False, 'URL is malformed: %s' % uri)
    else:
        if scheme not in supported_schemes:
            return (False, 'URI scheme: "%s" is not supported' % scheme)

    e = 'URL is valid'
    return True, e

def list_of_uris(attribute_value):
    
    e = ''
    all_valid = True
    for string in attribute_value:
        valid, explanation = valid_uri(string)
        if not valid:
            all_valid = False
            e.append(explanation)
        
    if not e:
        e = "List of valid URI strings accepted."
        
    return (all_valid, e)
    

format_definition = {
    # 'Attribute': (mandatory, value_type, default_value,
    #           description, example_value,
    #           supported_func
    #           )
    #
    # supported_func: Function recieves the value of the attribute
    # and returns a tuple: a boolean to indicate validity,
    # and a string describing what is valid / not valid.
    
    'Name': (True, 'string', None,
            'Name of the software', 'foo',
            any_string
            ),

    'Version': (True, 'string', None,
            'Version of the software', '1.0.0',
            any_string
            ),

    'ReleaseVersion': (True, 'string', '0',
            'Version of the package', '1',
            any_string
            ),

    'BriefDescription': (True, 'string', None,
            'Short description of the software',
            'foo is a well known example software',
            any_string
            ),

    'Description': (False, 'string', '',
            'Longer description of the software',
            'foos amazing capabilities and qualities has led it to become ubiquitous',
            any_string
            ),

    'URL': (True, 'string', None,
            'The homepage of the software',
            'http://www.example.org/foo',
            valid_uri
            ),

    'ProjectType': (True, 'string', None,
            'The type of project', 'python2-library',
            supported_project_type
            ),

    'BuildSystemType': (True, 'string', None,
            'The build system used.', 'autotools',
            supported_buildsystem
            ),

    'Licenses': (True, 'list-of-strings', None,
            'The licenses this software is under', 'GPL',
            list_of_any_strings
            ),

    'Dependencies': (True, 'list-of-strings', None,
            'The runtime dependencies of this software',
            ["pkg-config:glib-2.0","executable:gcc"],
            list_of_dependencies
            ),

    'BuildDependencies': (True, 'list-of-strings', None,
            'The buildtime dependencies of this software',
            ["pkg-config:glib-2.0","executable:gcc"],
            list_of_dependencies
            ),
            
    'Sources': (True, 'list-of-string', None,
            'The source code', [],
            list_of_uris
            ),

    # FIXME: should have a more flexible solutions, which
    # also allows other types of hashes like SHA256 etc.
    # SourceHashes: ['md5:HASH', 'sha256:HASH'] ?
    'Md5sums': (True, 'list-of-string', None,
            'The MD5 hashes for each entry in Source', [],
            list_of_any_strings
            ),
    
}


class RecipeVerificationResult(object):

    def __init__(self):
        self._errors = []
        self._warnings = []

    def _add_error(self, id, description):
        self._errors.append((id, description))

    def _add_warning(self, id, description):
        self._warnings.append((id, description))

    @property
    def errors(self):
        return self._errors

    @property
    def warnings(self):
        return self._warnings

    @property
    def passed(self):
        return not bool(self.errors)

    @property
    def has_warnings(self):
        return bool(self.warnings)

    def error_description(self):
        if not self.errors:
            return None

        return '\n'.join('Error: ' + desc for (id, desc) in self.errors)

    def warning_description(self):
        if not self.warnings:
            return None

        return '\n'.join('Warning: ' + desc for (id, desc) in self.warnings)

    def _status_str(self):
        status = ""

        if self.passed:
            status = "Passed"

        if self.has_warnings:
            status = "Warning"

        if not self.passed:
            status = "Failed"

        return status

    def __str__(self):
        return self._status_str()


def verify_recipe(recipe, format):
    """Verify that a recipe is valid against the given format.
    Returns a RecipeVerificationResult instance."""

    recipe_data = recipe.data
    result = RecipeVerificationResult()

    # Check that all mandatory attributes are present (ERROR)
    for attribute in format.mandatory_attributes:
        if not attribute in recipe_data.keys():
            result._add_error("missing-mandatory-attribute",
                    "Missing mandatory attribute \"%s\"" % attribute)

    # Check for unknown attributes (WARNING)
    for attribute in recipe_data.keys():
        if not attribute in format.all_attributes:
            result._add_warning("unrecognized-attribute",
                    "Unrecognised attribute \"%s\"" % attribute)

    # Check that all attributes have supported values (ERROR)
    for attribute, value in recipe_data.items():
        if not attribute in format.all_attributes:
            # Unknown
            continue

        supported_func = format.definition[attribute][5]

        supported, desc = supported_func(value)
        if not supported:
            result._add_error("unsupported-attribute-value",
                    "Value \"%s\" is not supported for attribute \"%s\". %s"
                    % (value, attribute, desc))

    return result



# TODO: rename to PackageRecipe
class GenericRecipeFormat(object):

    # FIXME: Formalize supported values
    # TODO: some more could probably be optional?
    # TODO: define default value for optional attributes
    # TODO: define a sorting order (for use in the documentation)

    definition = format_definition
    default = format_defaults(format_definition)
    example = format_example(format_definition)

    __doc__ = format_documentation(format_definition)

    # Disjunct sets
    mandatory_attributes = set(format_mandatory_attributes(format_definition))
    optional_attributes = set(format_optional_attributes(format_definition))

    all_attributes = set(format_attributes(format_definition))

    # Sanity checking
    assert mandatory_attributes.union(optional_attributes) == all_attributes
    assert not mandatory_attributes.intersection(optional_attributes)

class GenericRecipe(object):
    """Generic (target-independent) package recipe.
    Format is defined by GenericRecipeFormat."""


    def __init__(self):
        self._data = dict(GenericRecipeFormat.default)

    def verify(self):
        return verify_recipe(self, GenericRecipeFormat)

    def load(self, mapping):
        """Load the metadata from @mapping."""

        # TODO: warn on unknown input attributes
        # TODO: verify types of input attributes

        self._data = dict(GenericRecipeFormat.default)
        self._data.update(mapping)
        return self.verify()

    def load_from_string(self, string):
        """Load the metadata from @string in YAML format."""
        mapping = yaml.load(string)
        return self.load(mapping)

    def load_from_file(self, filepath):
        """Load the recipe metadata from @filepath."""
        file_contents = open(filepath).read()
        return self.load_from_string(file_contents)

    def get_data(self):
        # Return copy so that it cannot be mutated by others
        return dict(self._data)
    data = property(get_data)


# TODO: rename to 


"""
Recipe for how to build for a given target

The YAML format used is generated by DeploymentKit, and should
be considered an internal intermediate format. End-users should
concern themselves only with GenericRecipe
"""

build_recipe_format_definition = {
    # 'Attribute': (is_mandatory, value_type, default_value,
    #           description, example_value,
    #           supported_func
    #           )
    #
    # supported_func: Function recieves the value of the attribute
    # and returns a tuple: a boolean to indicate validity,
    # and a string describing what is valid / not valid.
        
    'Targets': (True, 'list-of-strings', None,
            'The targets for this build recipe', ['gnulinux-archlinux-current-x86_64'],
            list_of_any_strings
            ),

    'Files': (True, 'list-of-strings', None,
            """The files that are part of this build recipe.
            Paths are relative to the build.yaml file""", ['PKGBUILD'],
            list_of_any_strings
            ),
            
    'Toolchain': (True, 'string', None,
            "The toolchain to use for building.", "archlinux-native",
            any_string
            ),
            
    'ToolchainOptions': (False, 'string', {},
            "Options for the toolchain in use.", {'ToolchainSpecific1': 'SomeValue'},
            any_value
            ),
}


class BuildRecipe(object):
    """Target specific package recipe."""

    def __init__(self):
        self._data = {}

    def get_files(self):
        return self._data['Files']
    def set_files(self, files):
        self._data['Files'] = files
    files = property(get_files, set_files)

    def get_targets(self):
        return self._data['Targets']
    def set_targets(self, targets):
        self._data['Targets'] = targets
    targets = property(get_targets, set_targets)

    def get_toolchain(self):
        return self._data['Toolchain']
    def set_toolchain(self, toolchain):
        self._data['Toolchain'] = toolchain
    toolchain = property(get_toolchain, set_toolchain)

    def get_package_recipe(self):
        recipe = GenericRecipe()
        recipe.load(self._data['PackageRecipeData'])
        return recipe
    def set_package_recipe(self, recipe):
        self._data['PackageRecipeData'] = recipe.data
    package_recipe = property(get_package_recipe, set_package_recipe)

    def verify(self):
        return RecipeVerificationResult()

    def load(self, mapping):
        """"""
        self._data.update(mapping)
        return self.verify()
        
    def load_from_string(self, string):
        mapping = yaml.load(string)

    def get_data(self):
        return dict(self._data)
    data = property(get_data)

def build_recipes_from_file(path):
    
    recipes = yaml.load(open(path).read())
    
    def normalize(recipe):
        if not isinstance(recipe, BuildRecipe):        
            r = BuildRecipe()
            r.load(recipe)
            return r
        return recipe
        
    return [normalize(r) for r in recipes]

def write_build_recipes_to_directory(package_name, build_recipes, output_directory):
    
    # XXX: Should check that different recipes don't write the same files
    for recipe in build_recipes:
        write_build_recipe_files_to_directory(recipe, output_directory)
    
    build_recipe_content = yaml.dump([b.data for b in build_recipes])
    f = open(os.path.join(output_directory, package_name + '.build.yaml'), 'w')
    f.write(build_recipe_content)
    f.close()

def write_build_recipe_files_to_directory(build_recipe, path):

    output_prefix = path
    output_files = build_recipe.file_contents

    for filename, file_content in output_files.items():
        if not os.path.exists(output_prefix):
            os.makedirs(output_prefix)
        f = open(os.path.join(output_prefix, filename), 'w')
        f.write(file_content)
        f.close()


